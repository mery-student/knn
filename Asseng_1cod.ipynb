{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd0247e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 228 (1278483795.py, line 236)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 236\u001b[1;36m\u001b[0m\n\u001b[1;33m    def compute_l2_distance(test_point, training_points):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 228\n"
     ]
    }
   ],
   "source": [
    "#FILE NAME: knn_exercise.py    #########################################################################################\n",
    "# k-Nearest Neighbor (kNN) exercise\n",
    "# Complete and hand in this code completed (including its outputs and any supporting code outside of it)\n",
    "#\n",
    "# The kNN classifier consists of two stages:\n",
    "#\n",
    "#   During training, the classifier takes the training data and simply remembers it\n",
    "#   During testing,  kNN classifies every test image by comparing to all training images and\n",
    "#                    transfering the labels of the k most similar training examples\n",
    "# The value of k is cross-validated\n",
    "# In this exercise you will implement these steps and understand the basic Image Classification pipeline,\n",
    "# cross-validation, and gain proficiency in writing efficient, vectorized code.\n",
    "########################################################################################################################\n",
    "#FILE NAME: load_cifar10.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f, encoding='bytes')\n",
    "    X = datadict[b'data']    #datadict['data']   KeyError: 'data'\n",
    "    Y = datadict[b'labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\") #initial structure is 10000,3,1024\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):    # 5 train batches\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)\n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000,\n",
    "                     subtract_mean=True):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for classifiers. These are the same steps as we used for the SVM, but\n",
    "    condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'C:/Users/sadegi/anaconda3/cifar-10-batches-py/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    if subtract_mean:\n",
    "        mean_image = np.mean(X_train, axis=0)\n",
    "        X_train -= mean_image\n",
    "        X_val -= mean_image\n",
    "        X_test -= mean_image\n",
    "\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    # Package data into a dictionary\n",
    "    return {\n",
    "        'X_train': X_train, 'y_train': y_train,\n",
    "        'X_val': X_val, 'y_val': y_val,\n",
    "        'X_test': X_test, 'y_test': y_test,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from utilities.load_cifar10 import load_CIFAR10\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Load the raw CIFAR-10 data.\n",
    "# Change the following path to the directory that your \"cifar-10-batches-py\" file exists\n",
    "\n",
    "cifar10_dir = 'C:/Users/sadegi/anaconda3/cifar-10-batches-py'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, Y_train\n",
    "   del X_test, Y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', Y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', Y_test.shape)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(Y_train == y)  #find train data indexes with class y\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 500   #5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "Y_train = Y_train[mask]\n",
    "\n",
    "num_test = 50    #500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "Y_test = Y_test[mask]\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "#######################################################################################################################\n",
    "#FILE NAME: knn_classifier.py \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNearestNeighbor(object):\n",
    "    \"\"\" a kNN classifier with L2 distance \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train the classifier. For k-nearest neighbors this is just\n",
    "        memorizing the training data.\n",
    "\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (num_train, D) containing the training data\n",
    "          consisting of num_train samples each of dimension D.\n",
    "        - y: A numpy array of shape (N,) containing the training labels, where\n",
    "             y[i] is the label for X[i].\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.Y_train = Y\n",
    "\n",
    "    def predict(self, X, k=1, num_loops=0):\n",
    "        \"\"\"\n",
    "        Predict labels for test data using this classifier.\n",
    "\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (num_test, D) containing test data consisting\n",
    "             of num_test samples each of dimension D.\n",
    "        - k: The number of nearest neighbors that vote for the predicted labels.\n",
    "        - num_loops: Determines which implementation to use to compute distances\n",
    "          between training points and testing points.\n",
    "\n",
    "        Returns:\n",
    "        - y: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "          test data, where y[i] is the predicted label for the test point X[i].\n",
    "        \"\"\"\n",
    "        if num_loops == 0:\n",
    "            dists = self.compute_distances_no_loops(X)\n",
    "        elif num_loops == 1:\n",
    "            dists = self.compute_distances_one_loop(X)\n",
    "        elif num_loops == 2:\n",
    "            dists = self.compute_distances_two_loops(X)\n",
    "        else:\n",
    "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
    "\n",
    "        return self.predict_labels(dists, k=k)\n",
    "\n",
    "    def compute_distances_two_loops(self, X):\n",
    "        \"\"\"\n",
    "        Compute the distance between each test point in X and each training point\n",
    "        in self.X_train using a nested loop over both the training data and the\n",
    "        test data.\n",
    "\n",
    "        Inputs:\n",
    "        - X: A numpy array of shape (num_test, D) containing test data.\n",
    "\n",
    "        Returns:\n",
    "        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "          is the Euclidean distance between the ith test point and the jth training\n",
    "          point.\n",
    "        \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        for i in range(num_test):\n",
    "            for j in range(num_train):\n",
    "                #####################################################################\n",
    "                # TODO:                                                             #\n",
    "                # Compute the l2 distance between the ith test point and the jth    #\n",
    "                # training point, and store the result in dists[i, j]. You should   #\n",
    "                # not use a loop over dimension.                                    #\n",
    "                ##############################################################\n",
    "\n",
    "    def compute_l2_distance(test_point, training_points):\n",
    "       # محاسبه ماتریس فاصله بین نقاط آزمایشی و آموزشی\n",
    "       dists = np.sqrt(np.sum((test_point - training_points)**2, axis=1))\n",
    "       return dists\n",
    "        \n",
    "      # داده‌های آزمایشی و آموزشی شما\n",
    "      test_point = np.array([1, 2, 3])  # نقطه آزمایشی i\n",
    "      training_points = np.array([[4, 5, 6], [7, 8, 9], [10, 11, 12]])  # نقاط آموزشی j\n",
    "\n",
    "         # محاسبه فاصله L2 بین نقطه آزمایشی i و نقاط آموزشی j\n",
    "        distances = compute_l2_distance(test_point, training_points)\n",
    "\n",
    "        print(distances)\n",
    "                pass\n",
    "                #####################################################################\n",
    "                #                       END OF YOUR CODE                            #\n",
    "                #####################################################################\n",
    "        return dists\n",
    "\n",
    "    def compute_distances_one_loop(self, X):\n",
    "        \"\"\"\n",
    "        Compute the distance between each test point in X and each training point\n",
    "        in self.X_train using a single loop over the test data.\n",
    "\n",
    "        Input / Output: Same as compute_distances_two_loops\n",
    "        \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        for i in range(num_test):\n",
    "            #######################################################################\n",
    "            # TODO:                                                               #\n",
    "            # Compute the l2 distance between the ith test point and all training #\n",
    "            # points, and store the result in dists[i, :].                        #\n",
    "            #######################################################################\n",
    "            pass\n",
    "            #######################################################################\n",
    "            #                         END OF YOUR CODE                            #\n",
    "            #######################################################################\n",
    "        return dists\n",
    "\n",
    "    def compute_distances_no_loops(self, X):\n",
    "        \"\"\"\n",
    "        Compute the distance between each test point in X and each training point\n",
    "        in self.X_train using no explicit loops.\n",
    "\n",
    "        Input / Output: Same as compute_distances_two_loops\n",
    "        \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        num_train = self.X_train.shape[0]\n",
    "        dists = np.zeros((num_test, num_train))\n",
    "        #########################################################################\n",
    "        # TODO:                                                                 #\n",
    "        # Compute the l2 distance between all test points and all training      #\n",
    "        # points without using any explicit loops, and store the result in      #\n",
    "        # dists.                                                                #\n",
    "        #                                                                       #\n",
    "        # You should implement this function using only basic array operations; #\n",
    "        # in particular you should not use functions from scipy.                #\n",
    "        #                                                                       #\n",
    "        # HINT: Try to formulate the l2 distance using matrix multiplication    #\n",
    "        #       and two broadcast sums.                                         #\n",
    "        #########################################################################\n",
    "        pass\n",
    "        #########################################################################\n",
    "        #                         END OF YOUR CODE                              #\n",
    "        #########################################################################\n",
    "        return dists\n",
    "\n",
    "    def predict_labels(self, dists, k=1):\n",
    "        \"\"\"\n",
    "        Given a matrix of distances between test points and training points,\n",
    "        predict a label for each test point.\n",
    "\n",
    "        Inputs:\n",
    "        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "          gives the distance between the ith test point and the jth training point.\n",
    "\n",
    "        Returns:\n",
    "        - y: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "          test data, where y[i] is the predicted label for the test point X[i].\n",
    "        \"\"\"\n",
    "        num_test = dists.shape[0]\n",
    "        Y_pred = np.zeros(num_test)\n",
    "        for i in range(num_test):\n",
    "            # A list of length k storing the labels of the k nearest neighbors to\n",
    "            # the ith test point.\n",
    "            closest_y = []\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Use the distance matrix to find the k nearest neighbors of the ith    #\n",
    "            # testing point, and use self.Y_train to find the labels of these       #\n",
    "            # neighbors. Store these labels in closest_y.                           #\n",
    "            # Hint: Look up the function numpy.argsort.                             #\n",
    "            #########################################################################\n",
    "            pass\n",
    "            #########################################################################\n",
    "            # TODO:                                                                 #\n",
    "            # Now that you have found the labels of the k nearest neighbors, you    #\n",
    "            # need to find the most common label in the list closest_y of labels.   #\n",
    "            # Store this label in Y_pred[i]. Break ties by choosing the smaller     #\n",
    "            # label.                                                                #\n",
    "            # HINT: Look up the \"Counter\" from \"collections\".                       #\n",
    "            #########################################################################\n",
    "            pass\n",
    "            #########################################################################\n",
    "            #                           END OF YOUR CODE                            #\n",
    "            #########################################################################\n",
    "\n",
    "        return Y_pred\n",
    "\n",
    "###########################################################################################################3\n",
    "\n",
    "##from classifiers.knn_classifier import KNearestNeighbor\n",
    "\n",
    "# Create a kNN classifier instance.\n",
    "# Remember that training a kNN classifier is a noop:\n",
    "# the Classifier simply remembers the data and does no further processing\n",
    "knn_model = KNearestNeighbor()\n",
    "knn_model.train(X_train, Y_train)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# open classifiers/knn_classifier.py and implement the function \"compute_distances_two_loops\" that\n",
    "# uses a (very inefficient) double loop over all pairs of (test, train) examples and\n",
    "# computes the distance matrix one element at a time.\n",
    "\n",
    "# Test your implementation:\n",
    "dists = knn_model.compute_distances_two_loops(X_test)\n",
    "print(dists.shape)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# We can visualize the distance matrix: each row is for a single test example and\n",
    "# its distances to all training examples\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.show()\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Now implement the function \"predict_labels\" in classifiers/knn_classifier.py\n",
    "# and run the code below: We use k = 1 (which is Nearest Neighbor).\n",
    "Y_test_pred = knn_model.predict_labels(dists, k=1)\n",
    "\n",
    "# Compute and print the fraction of correctly predicted examples\n",
    "num_correct = np.sum(Y_test_pred == Y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('For k=1 we got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "# You should expect to see approximately 27% accuracy.\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Now lets try out a larger k, say k = 5:\n",
    "Y_test_pred = knn_model.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(Y_test_pred == Y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('For k=5 we got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "# You should expect to see a slightly better performance than with k = 1.\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Now lets speed up distance matrix computation by using partial vectorization\n",
    "# with one loop. Implement the function \"compute_distances_one_loop\" in\n",
    "# classifiers/knn_classifier.py and run the code below:\n",
    "dists_one = knn_model.compute_distances_one_loop(X_test)\n",
    "\n",
    "# To ensure that our vectorized implementation is correct, we make sure that it\n",
    "# agrees with the naive implementation. There are many ways to decide whether\n",
    "# two matrices are similar; one of the simplest is the Frobenius norm. In case\n",
    "# you haven't seen it before, the Frobenius norm of two matrices is the square\n",
    "# root of the squared sum of differences of all elements; in other words, reshape\n",
    "# the matrices into vectors and compute the Euclidean distance between them.\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Now implement the fully vectorized version inside \"compute_distances_no_loops\" function\n",
    "# and run the code\n",
    "dists_two = knn_model.compute_distances_no_loops(X_test)\n",
    "\n",
    "# check that the distance matrix agrees with the one we computed before:\n",
    "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Let's compare how fast the implementations are\n",
    "def time_function(f, *args):\n",
    "    #Call a function f with its args and return the time (in seconds) that it took to execute.\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "two_loop_time = time_function(knn_model.compute_distances_two_loops, X_test)\n",
    "print('Two loop version took %f seconds' % two_loop_time)\n",
    "\n",
    "one_loop_time = time_function(knn_model.compute_distances_one_loop, X_test)\n",
    "print('One loop version took %f seconds' % one_loop_time)\n",
    "\n",
    "no_loop_time = time_function(knn_model.compute_distances_no_loops, X_test)\n",
    "print('No loop version took %f seconds' % no_loop_time)\n",
    "\n",
    "# you should see significantly faster performance with the fully vectorized implementation\n",
    "\n",
    "#######################################################################################################################\n",
    "# Cross-validation\n",
    "# We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily.\n",
    "# We will now determine the best value of this hyperparameter with cross-validation.\n",
    "#######################################################################################################################\n",
    "\n",
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "Y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# Y_train_folds should each be lists of length num_folds, where                #\n",
    "# Y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "# Your code\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# We define \"k_to_accuracies\" as a dictionary\n",
    "# holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "for k in k_choices:\n",
    "    k_to_accuracies[k]=[]\n",
    "    for j in range(num_folds):\n",
    "        pass  #delete 'pass' and write your code here\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Based on the cross-validation results above, choose the best value for k,\n",
    "# retrain the classifier using all the training data, and test it on the test\n",
    "# data. You should be able to get above 28% accuracy on the test data.\n",
    "\n",
    "best_k = 1    # this is for num_train=500 and num_test=50\n",
    "\n",
    "knn_model = KNearestNeighbor()\n",
    "knn_model.train(X_train, Y_train)\n",
    "Y_test_pred = knn_model.predict(X_test, k=best_k)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "num_correct = np.sum(Y_test_pred == Y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a9bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdf5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
